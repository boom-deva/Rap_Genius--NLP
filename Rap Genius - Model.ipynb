{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Rap Genius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "for topic modeling we are going to be using a technique called Laten Dirichlet Allocation (LDA). NLTK for part of speech tagging. We want to know what are the different themes that arise in a rappers lyrics, and who tends to talk about what.\n",
    "\n",
    "LDA deals with probability. Dirichlet is a type of probability and we are trying to discover what is the probability that the document is about a specific topic given a set of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1 -- All Text\n",
    "This is not going to work the first time through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:50:38.093567Z",
     "start_time": "2019-05-15T20:50:38.084158Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import matutils, models # matutils will turn the array into a bag of words\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T19:40:46.644167Z",
     "start_time": "2019-05-15T19:40:46.587160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>02</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1008</th>\n",
       "      <th>10yearolds</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>125</th>\n",
       "      <th>140</th>\n",
       "      <th>...</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zip</th>\n",
       "      <th>zod</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zonin</th>\n",
       "      <th>zöld</th>\n",
       "      <th>ölén</th>\n",
       "      <th>úgy</th>\n",
       "      <th>な音楽</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drake</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jayz</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nas</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KanyeWest</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 5270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           02  10  100  1000  1008  10yearolds  11  12  125  140  ...  zeros  \\\n",
       "Artist                                                            ...          \n",
       "Drake       0   0    6     0     0           0   0   0    0    0  ...      0   \n",
       "Jayz        0   0    2     0     0           0   2   0    0    1  ...      0   \n",
       "Nas         0   1    0     1     0           0   0   1    0    0  ...      1   \n",
       "Eminem      1   0    0     0     0           1   0   1    0    0  ...      0   \n",
       "Future      0   0    0     0     1           0   0   2    0    0  ...      0   \n",
       "KanyeWest   0   0    0     0     0           0   0   1    2    0  ...      0   \n",
       "\n",
       "           zip  zod  zombie  zone  zonin  zöld  ölén  úgy  な音楽  \n",
       "Artist                                                          \n",
       "Drake        1    0       0     1      0     0     0    0    0  \n",
       "Jayz         0    0       0     0      0     0     0    0    0  \n",
       "Nas          0    0       0     0      0     0     0    0    0  \n",
       "Eminem       0    1       1     0      0     0     0    0    0  \n",
       "Future       0    0       0     0      0     0     0    0    1  \n",
       "KanyeWest    0    0       1     0      3     1     1    1    0  \n",
       "\n",
       "[6 rows x 5270 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('DataFrame_with_new_stopwords.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T19:45:01.067622Z",
     "start_time": "2019-05-15T19:45:01.028469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Artist</th>\n",
       "      <th>Drake</th>\n",
       "      <th>Jayz</th>\n",
       "      <th>Nas</th>\n",
       "      <th>Eminem</th>\n",
       "      <th>Future</th>\n",
       "      <th>KanyeWest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Artist  Drake  Jayz  Nas  Eminem  Future  KanyeWest\n",
       "02          0     0    0       1       0          0\n",
       "10          0     0    1       0       0          0\n",
       "100         6     2    0       0       0          0\n",
       "1000        0     0    1       0       0          0\n",
       "1008        0     0    0       0       1          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose to create a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T19:49:55.477444Z",
     "start_time": "2019-05-15T19:49:55.465593Z"
    }
   },
   "outputs": [],
   "source": [
    "# now we are going to turn the tdm into a sparse matrix\n",
    "# where most of the elements are zero (the opposite is a dense matrix where they are nonzero)\n",
    "\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T19:58:25.431749Z",
     "start_time": "2019-05-15T19:58:25.395317Z"
    }
   },
   "outputs": [],
   "source": [
    "# gensim requires a dictionary of all the terms and where they reside in the tdm\n",
    "# this will show us all the unique words in our corpus.\n",
    "cv = pickle.load(open('cv_stop.pkl', 'rb'))\n",
    "id2word = dict((v,k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T19:58:26.468811Z",
     "start_time": "2019-05-15T19:58:26.420628Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3548: 'produced',\n",
       " 531: 'boi1da',\n",
       " 1753: 'frank',\n",
       " 1405: 'dukes',\n",
       " 3092: 'noah',\n",
       " 34: '40',\n",
       " 4063: 'shebib',\n",
       " 3086: 'nineteen85',\n",
       " 2: '100',\n",
       " 4921: 'verse',\n",
       " 396: 'bein',\n",
       " 846: 'chill',\n",
       " 3692: 'real',\n",
       " 3630: 'quick',\n",
       " 3667: 'raptopaythebill',\n",
       " 1615: 'feel',\n",
       " 2631: 'little',\n",
       " 454: 'bit',\n",
       " 3151: 'oh',\n",
       " 2668: 'lord',\n",
       " 5175: 'worth',\n",
       " 95: 'actions',\n",
       " 2680: 'louder',\n",
       " 5161: 'words',\n",
       " 2084: 'high',\n",
       " 1431: 'earth',\n",
       " 5000: 'wanna',\n",
       " 4816: 'turf',\n",
       " 3866: 'rookie',\n",
       " 4926: 'vet',\n",
       " 4107: 'shoutout',\n",
       " 456: 'bitches',\n",
       " 2114: 'holdin',\n",
       " 4034: 'set',\n",
       " 3357: 'phone',\n",
       " 2661: 'lookin',\n",
       " 3373: 'pictures',\n",
       " 3077: 'night',\n",
       " 1890: 'gon',\n",
       " 4883: 'upset',\n",
       " 3986: 'scrollin',\n",
       " 2558: 'left',\n",
       " 1186: 'dawg',\n",
       " 3690: 'ready',\n",
       " 1928: 'greatest',\n",
       " 2045: 'headed',\n",
       " 2825: 'mean',\n",
       " 5030: 'way',\n",
       " 1774: 'friendly',\n",
       " 2533: 'lay',\n",
       " 2967: 'mothafuckin',\n",
       " 4393: 'steph',\n",
       " 1138: 'curry',\n",
       " 4097: 'shot',\n",
       " 1029: 'cookin',\n",
       " 3946: 'sauce',\n",
       " 827: 'chef',\n",
       " 3483: 'pot',\n",
       " 569: 'boy',\n",
       " 32: '360',\n",
       " 5189: 'wrist',\n",
       " 3222: 'ovo',\n",
       " 3699: 'really',\n",
       " 4082: 'shits',\n",
       " 3556: 'prolly',\n",
       " 4126: 'sign',\n",
       " 2103: 'hitboy',\n",
       " 2106: 'hits',\n",
       " 1357: 'drake',\n",
       " 1905: 'gotta',\n",
       " 2611: 'lil',\n",
       " 2983: 'mouse',\n",
       " 1371: 'drill',\n",
       " 3668: 'raptopayyourbill',\n",
       " 3669: 'raptorspaymybills',\n",
       " 4827: 'tv',\n",
       " 4657: 'thought',\n",
       " 2297: 'itd',\n",
       " 2746: 'make',\n",
       " 3806: 'richer',\n",
       " 5017: 'wasnt',\n",
       " 3300: 'payin',\n",
       " 3052: 'needed',\n",
       " 4263: 'somethin',\n",
       " 3631: 'quicker',\n",
       " 3083: 'nikos',\n",
       " 344: 'basement',\n",
       " 3614: 'puttin',\n",
       " 5163: 'work',\n",
       " 3358: 'phones',\n",
       " 1375: 'drive',\n",
       " 2946: 'money',\n",
       " 2782: 'mart',\n",
       " 3370: 'pickups',\n",
       " 14: '2008',\n",
       " 4808: 'tryna',\n",
       " 3245: 'paint',\n",
       " 3372: 'picture',\n",
       " 969: 'comeback',\n",
       " 3997: 'season',\n",
       " 5167: 'works',\n",
       " 4643: 'thinkin',\n",
       " 432: 'bigger',\n",
       " 4460: 'studio',\n",
       " 2517: 'late',\n",
       " 5022: 'watch',\n",
       " 5002: 'want',\n",
       " 4119: 'sicker',\n",
       " 2674: 'lot',\n",
       " 2385: 'just',\n",
       " 642: 'bucks',\n",
       " 444: 'billis',\n",
       " 2431: 'kill',\n",
       " 1873: 'goats',\n",
       " 3898: 'run',\n",
       " 1740: 'forrest',\n",
       " 5197: 'wrote',\n",
       " 1166: 'damn',\n",
       " 5074: 'whats',\n",
       " 3633: 'quote',\n",
       " 4281: 'soundin',\n",
       " 2300: 'ive',\n",
       " 1154: 'dad',\n",
       " 4888: 'used',\n",
       " 4606: 'tell',\n",
       " 973: 'comin',\n",
       " 2156: 'house',\n",
       " 4899: 'valuable',\n",
       " 2573: 'lesson',\n",
       " 1945: 'grow',\n",
       " 231: 'ask',\n",
       " 2065: 'help',\n",
       " 2206: 'ill',\n",
       " 3212: 'outro',\n",
       " 4339: 'squad',\n",
       " 1787: 'fuckin',\n",
       " 2202: 'ii',\n",
       " 756: 'catch',\n",
       " 603: 'bridge',\n",
       " 2528: 'lavish',\n",
       " 2557: 'lee',\n",
       " 4708: 'told',\n",
       " 3328: 'people',\n",
       " 2628: 'listen',\n",
       " 3915: 'said',\n",
       " 4859: 'unconditional',\n",
       " 2214: 'imagine',\n",
       " 1301: 'dissin',\n",
       " 3158: 'okay',\n",
       " 3344: 'perspective',\n",
       " 4567: 'talkin',\n",
       " 564: 'bout',\n",
       " 4249: 'soften',\n",
       " 2673: 'lost',\n",
       " 1470: 'em',\n",
       " 2813: 'maybe',\n",
       " 2669: 'lose',\n",
       " 2991: 'movin',\n",
       " 1743: 'forward',\n",
       " 4635: 'theyre',\n",
       " 4356: 'stagnant',\n",
       " 3051: 'need',\n",
       " 1608: 'favor',\n",
       " 3995: 'searchin',\n",
       " 3544: 'problems',\n",
       " 233: 'askin',\n",
       " 2281: 'involved',\n",
       " 1711: 'focused',\n",
       " 3329: 'peoples',\n",
       " 1614: 'feedback',\n",
       " 3577: 'provin',\n",
       " 5195: 'wrong',\n",
       " 3952: 'say',\n",
       " 4084: 'shoe',\n",
       " 1664: 'fit',\n",
       " 2804: 'matter',\n",
       " 1722: 'foot',\n",
       " 1191: 'days',\n",
       " 4344: 'squeezin',\n",
       " 5162: 'wore',\n",
       " 431: 'big',\n",
       " 2550: 'leave',\n",
       " 1803: 'game',\n",
       " 3992: 'seams',\n",
       " 4323: 'splittin',\n",
       " 3593: 'pun',\n",
       " 2263: 'intended',\n",
       " 4215: 'smellin',\n",
       " 1214: 'defeat',\n",
       " 145: 'air',\n",
       " 4720: 'took',\n",
       " 2839: 'meetin',\n",
       " 2075: 'hes',\n",
       " 1095: 'crazy',\n",
       " 1311: 'doesnt',\n",
       " 731: 'care',\n",
       " 2172: 'humble',\n",
       " 268: 'aware',\n",
       " 424: 'better',\n",
       " 1442: 'eavesdroppin',\n",
       " 4334: 'spring',\n",
       " 15: '2015',\n",
       " 3465: 'poppin',\n",
       " 3432: 'pnd',\n",
       " 1384: 'droppin',\n",
       " 3767: 'repsup',\n",
       " 2745: 'majid',\n",
       " 2360: 'jordan',\n",
       " 3134: 'ob',\n",
       " 2858: 'mention',\n",
       " 3242: 'paid',\n",
       " 3726: 'refs',\n",
       " 1667: 'fixed',\n",
       " 3095: 'noel',\n",
       " 4834: 'twitter',\n",
       " 3034: 'names',\n",
       " 2548: 'lease',\n",
       " 3340: 'person',\n",
       " 2405: 'keepin',\n",
       " 3287: 'past',\n",
       " 4613: 'tense',\n",
       " 2796: 'match',\n",
       " 26: '27',\n",
       " 1839: 'gettin',\n",
       " 2036: 'havent',\n",
       " 3284: 'passed',\n",
       " 2317: 'james',\n",
       " 469: 'blake',\n",
       " 4882: 'upproduced',\n",
       " 2416: 'key',\n",
       " 4998: 'wane',\n",
       " 2273: 'intro',\n",
       " 277: 'aziz',\n",
       " 184: 'ansari',\n",
       " 4396: 'stepping',\n",
       " 4368: 'start',\n",
       " 3301: 'paying',\n",
       " 1760: 'free',\n",
       " 3655: 'randy',\n",
       " 866: 'chorus',\n",
       " 986: 'complain',\n",
       " 1734: 'forgot',\n",
       " 2904: 'mind',\n",
       " 708: 'came',\n",
       " 4383: 'stay',\n",
       " 4798: 'true',\n",
       " 786: 'chainz',\n",
       " 4642: 'think',\n",
       " 2367: 'js',\n",
       " 3393: 'pinky',\n",
       " 3826: 'ring',\n",
       " 1313: 'dogging',\n",
       " 2110: 'hoes',\n",
       " 3621: 'quarantine',\n",
       " 2540: 'league',\n",
       " 308: 'ball',\n",
       " 137: 'ah',\n",
       " 1587: 'fame',\n",
       " 2048: 'hear',\n",
       " 4691: 'time',\n",
       " 279: 'baby',\n",
       " 1848: 'girl',\n",
       " 1583: 'fall',\n",
       " 2615: 'line',\n",
       " 2899: 'million',\n",
       " 1282: 'dinner',\n",
       " 1736: 'fork',\n",
       " 4538: 'switch',\n",
       " 4987: 'walked',\n",
       " 156: 'alert',\n",
       " 998: 'condo',\n",
       " 559: 'bought',\n",
       " 4077: 'shirt',\n",
       " 1056: 'cost',\n",
       " 2860: 'mercedesbenz',\n",
       " 727: 'car',\n",
       " 3112: 'note',\n",
       " 4727: 'toronto',\n",
       " 2574: 'let',\n",
       " 2869: 'metal',\n",
       " 1259: 'dick',\n",
       " 2014: 'hard',\n",
       " 1244: 'detector',\n",
       " 1369: 'dressing',\n",
       " 1853: 'givenchy',\n",
       " 486: 'bless',\n",
       " 2038: 'having',\n",
       " 299: 'bad',\n",
       " 455: 'bitch',\n",
       " 1107: 'crime',\n",
       " 2192: 'id',\n",
       " 216: 'arrested',\n",
       " 4797: 'tru',\n",
       " 4731: 'touched',\n",
       " 55: '86',\n",
       " 2459: 'knew',\n",
       " 133: 'age',\n",
       " 1785: 'fucked',\n",
       " 283: 'babysit',\n",
       " 5221: 'years',\n",
       " 2519: 'later',\n",
       " 2049: 'heard',\n",
       " 3065: 'new',\n",
       " 2030: 'hated',\n",
       " 1168: 'damon',\n",
       " 5031: 'wayans',\n",
       " 2130: 'homie',\n",
       " 3417: 'play',\n",
       " 2520: 'latest',\n",
       " 5133: 'wishing',\n",
       " 5210: 'yall',\n",
       " 1271: 'different',\n",
       " 1517: 'everybody',\n",
       " 2973: 'motherfucking',\n",
       " 748: 'cashing',\n",
       " 822: 'checks',\n",
       " 436: 'bigging',\n",
       " 829: 'chest',\n",
       " 4568: 'talking',\n",
       " 1838: 'gets',\n",
       " 4527: 'swear',\n",
       " 5021: 'wasting',\n",
       " 592: 'breath',\n",
       " 2603: 'light',\n",
       " 4163: 'skinned',\n",
       " 2407: 'keith',\n",
       " 4528: 'sweat',\n",
       " 2212: 'ima',\n",
       " 1730: 'forever',\n",
       " 4818: 'turn',\n",
       " 2659: 'look',\n",
       " 4864: 'understand',\n",
       " 3856: 'roll',\n",
       " 1059: 'cottonelle',\n",
       " 3838: 'road',\n",
       " 568: 'box',\n",
       " 3145: 'office',\n",
       " 3922: 'sales',\n",
       " 1840: 'getting',\n",
       " 1531: 'excuse',\n",
       " 4552: 'table',\n",
       " 2761: 'manners',\n",
       " 2750: 'making',\n",
       " 3867: 'room',\n",
       " 1171: 'dancers',\n",
       " 2371: 'judging',\n",
       " 117: 'advances',\n",
       " 3993: 'sean',\n",
       " 2109: 'ho',\n",
       " 4116: 'shut',\n",
       " 2855: 'mental',\n",
       " 2544: 'learn',\n",
       " 1660: 'finna',\n",
       " 1265: 'didnt',\n",
       " 4985: 'waking',\n",
       " 3758: 'rents',\n",
       " 989: 'complicated',\n",
       " 4134: 'simple',\n",
       " 4044: 'sexy',\n",
       " 2496: 'ladies',\n",
       " 415: 'benzfull',\n",
       " 1519: 'everythingeverything',\n",
       " 1834: 'gentle',\n",
       " 1950: 'guess',\n",
       " 3159: 'old',\n",
       " 1599: 'fashioned',\n",
       " 5039: 'wearing',\n",
       " 3781: 'retro',\n",
       " 1598: 'fashion',\n",
       " 3954: 'saying',\n",
       " 927: 'closed',\n",
       " 725: 'caption',\n",
       " 3371: 'pics',\n",
       " 1894: 'good',\n",
       " 4042: 'sex',\n",
       " 2102: 'hit',\n",
       " 608: 'broad',\n",
       " 1696: 'floor',\n",
       " 5220: 'year',\n",
       " 3878: 'round',\n",
       " 4680: 'tickets',\n",
       " 3424: 'plead',\n",
       " 1638: 'fifth',\n",
       " 1372: 'drink',\n",
       " 2641: 'load',\n",
       " 4322: 'split',\n",
       " 1983: 'half',\n",
       " 4220: 'smoke',\n",
       " 5261: 'zip',\n",
       " 1862: 'glee',\n",
       " 3543: 'probably',\n",
       " 63: '99',\n",
       " 3805: 'rich',\n",
       " 4802: 'trust',\n",
       " 2296: 'issues',\n",
       " 4274: 'sorry',\n",
       " 3608: 'pushed',\n",
       " 4842: 'type',\n",
       " 660: 'bulletproof',\n",
       " 999: 'condom',\n",
       " 3583: 'pull',\n",
       " 3333: 'perfect',\n",
       " 3918: 'saint',\n",
       " 4640: 'thing',\n",
       " 2033: 'hating',\n",
       " 5166: 'working',\n",
       " 5149: 'women',\n",
       " 30: '305',\n",
       " 1726: 'fore',\n",
       " 1485: 'end',\n",
       " 2442: 'king',\n",
       " 1256: 'diamonds',\n",
       " 4692: 'times',\n",
       " 4222: 'smoking',\n",
       " 2483: 'kush',\n",
       " 4004: 'section',\n",
       " 2562: 'legalized',\n",
       " 1263: 'did',\n",
       " 4073: 'shine',\n",
       " 1437: 'eat',\n",
       " 4588: 'taught',\n",
       " 2645: 'loan',\n",
       " 4258: 'somebody',\n",
       " 3820: 'right',\n",
       " 487: 'blessed',\n",
       " 3002: 'muhfucka',\n",
       " 4443: 'stressed',\n",
       " 3059: 'nervous',\n",
       " 933: 'clutching',\n",
       " 831: 'chests',\n",
       " 2970: 'motherfucker',\n",
       " 4803: 'truth',\n",
       " 2596: 'lied',\n",
       " 4076: 'ship',\n",
       " 5156: 'wont',\n",
       " 3916: 'sail',\n",
       " 5112: 'wind',\n",
       " 1952: 'guide',\n",
       " 1156: 'daddy',\n",
       " 2312: 'jail',\n",
       " 5114: 'window',\n",
       " 1377: 'drivethru',\n",
       " 1317: 'dointro',\n",
       " 2545: 'learned',\n",
       " 5105: 'william',\n",
       " 5064: 'wesley',\n",
       " 820: 'check',\n",
       " 2864: 'message',\n",
       " 1079: 'cover',\n",
       " 2575: 'lethal',\n",
       " 5036: 'weapon',\n",
       " 61: '96',\n",
       " 62: '97',\n",
       " 5089: 'whoavery',\n",
       " 2221: 'important',\n",
       " 3530: 'pretentious',\n",
       " 2725: 'mad',\n",
       " 1820: 'gave',\n",
       " 248: 'attention',\n",
       " 5052: 'weighin',\n",
       " 2055: 'heavy',\n",
       " 1012: 'conscience',\n",
       " 3195: 'options',\n",
       " 2251: 'insane',\n",
       " 4392: 'step',\n",
       " 1750: 'frame',\n",
       " 690: 'buy',\n",
       " 556: 'bottles',\n",
       " 806: 'charlamagne',\n",
       " 4981: 'waited',\n",
       " 1388: 'drove',\n",
       " 5183: 'wraith',\n",
       " 3421: 'playin',\n",
       " 206: 'arab',\n",
       " 4512: 'sure',\n",
       " 3657: 'rap',\n",
       " 5139: 'woah',\n",
       " 1720: 'fool',\n",
       " 890: 'city',\n",
       " 4001: 'second',\n",
       " 4724: 'tootsies',\n",
       " 4103: 'shoulder',\n",
       " 3888: 'rubs',\n",
       " 5190: 'write',\n",
       " 2881: 'midas',\n",
       " 4730: 'touch',\n",
       " 4736: 'tour',\n",
       " 1850: 'girls',\n",
       " 4674: 'thug',\n",
       " 2827: 'meant',\n",
       " 3186: 'open',\n",
       " 4780: 'trigger',\n",
       " 1656: 'fingers',\n",
       " 526: 'bodied',\n",
       " 4140: 'singin',\n",
       " 4626: 'thatll',\n",
       " 553: 'boss',\n",
       " 5100: 'wifin',\n",
       " 3519: 'prenup',\n",
       " 1432: 'ease',\n",
       " 1884: 'going',\n",
       " 1776: 'friends',\n",
       " 1380: 'drizzy',\n",
       " 4016: 'sellout',\n",
       " 1515: 'event',\n",
       " 3999: 'seatin',\n",
       " 3705: 'reason',\n",
       " 3438: 'point',\n",
       " 4806: 'tryin',\n",
       " 4007: 'seen',\n",
       " 5238: 'youd',\n",
       " 1764: 'freedom',\n",
       " 5127: 'wire',\n",
       " 1428: 'earpiece',\n",
       " 3049: 'near',\n",
       " 968: 'come',\n",
       " 1927: 'great',\n",
       " 5092: 'whos',\n",
       " 4418: 'stop',\n",
       " 520: 'boasy',\n",
       " 1971: 'gwanin',\n",
       " 5018: 'wassy',\n",
       " 1632: 'fest',\n",
       " 4271: 'soon',\n",
       " 4355: 'stage',\n",
       " 586: 'break',\n",
       " 4939: 'views',\n",
       " 4154: 'sixchorus',\n",
       " 2654: 'long',\n",
       " 1580: 'fake',\n",
       " 4112: 'showin',\n",
       " 4426: 'straight',\n",
       " 1559: 'face',\n",
       " 2083: 'hidin',\n",
       " 4254: 'solid',\n",
       " 4266: 'son',\n",
       " 3684: 'reach',\n",
       " 3511: 'prechorus',\n",
       " 4217: 'smile',\n",
       " 3405: 'place',\n",
       " 5160: 'word',\n",
       " 2923: 'mistakes',\n",
       " 3913: 'safe',\n",
       " 4932: 'vibe',\n",
       " 1187: 'day',\n",
       " 269: 'away',\n",
       " 797: 'changed',\n",
       " 760: 'caught',\n",
       " 4641: 'things',\n",
       " 4169: 'skrrt',\n",
       " 881: 'chune',\n",
       " 2047: 'headtop',\n",
       " 4295: 'speak',\n",
       " 2469: 'knowintro',\n",
       " 5132: 'wishin',\n",
       " 5250: 'yuh',\n",
       " 707: 'calm',\n",
       " 4796: 'trouble',\n",
       " 3307: 'peaceful',\n",
       " 4456: 'struggle',\n",
       " 1130: 'cuddle',\n",
       " 2689: 'lovin',\n",
       " 1266: 'die',\n",
       " 2918: 'miss',\n",
       " 5230: 'yes',\n",
       " 2141: 'hope',\n",
       " 624: 'brothers',\n",
       " 3209: 'outlive',\n",
       " 4424: 'story',\n",
       " 1880: 'gods',\n",
       " 3408: 'plan',\n",
       " 2113: 'hold',\n",
       " 274: 'ayy',\n",
       " 1653: 'finessed',\n",
       " 5068: 'weston',\n",
       " 3061: 'nessed',\n",
       " 4980: 'wait',\n",
       " 4286: 'southside',\n",
       " 3109: 'northside',\n",
       " 3479: 'postchorus',\n",
       " 3278: 'partly',\n",
       " 379: 'bed',\n",
       " 2754: 'mama',\n",
       " 1399: 'dub',\n",
       " 4584: 'tatted',\n",
       " 54: '81',\n",
       " 4634: 'theyll',\n",
       " 605: 'bring',\n",
       " 1093: 'crashers',\n",
       " 3282: 'party',\n",
       " 3131: 'o2',\n",
       " 3132: 'o3',\n",
       " 1312: 'dog',\n",
       " 3162: 'oli',\n",
       " 4631: 'thered',\n",
       " 2733: 'magine',\n",
       " 2868: 'met',\n",
       " 621: 'broskies',\n",
       " 5024: 'watchin',\n",
       " 926: 'close',\n",
       " 5229: 'yep',\n",
       " 3960: 'scarlett',\n",
       " 5218: 'yeahproduced',\n",
       " 3724: 'refrain',\n",
       " 1555: 'eyes',\n",
       " 2149: 'hot',\n",
       " 1477: 'emotion',\n",
       " 1487: 'endlessly',\n",
       " 2777: 'mark',\n",
       " 3516: 'prehook',\n",
       " 89: 'act',\n",
       " 1526: 'exactly',\n",
       " 2138: 'hook',\n",
       " 2125: 'home',\n",
       " 151: 'al',\n",
       " 2789: 'maskati',\n",
       " 2685: 'loved',\n",
       " 4632: 'theres',\n",
       " 2126: 'homeintro',\n",
       " 774: 'cell',\n",
       " 2152: 'hotline',\n",
       " 495: 'bling',\n",
       " 3768: 'reputation',\n",
       " 2472: 'knows',\n",
       " 4369: 'started',\n",
       " 1883: 'goin',\n",
       " 1860: 'glasses',\n",
       " 790: 'champagne',\n",
       " 1169: 'dance',\n",
       " 2005: 'hangin',\n",
       " 3406: 'places',\n",
       " 404: 'belong',\n",
       " 232: 'asked',\n",
       " 3904: 'running',\n",
       " 3241: 'pages',\n",
       " 3286: 'passport',\n",
       " 5151: 'wonder',\n",
       " 409: 'bendin',\n",
       " 295: 'backwards',\n",
       " 3858: 'rolling',\n",
       " 297: 'backwoods',\n",
       " 1316: 'doing',\n",
       " 3041: 'nasty',\n",
       " 4732: 'touching',\n",
       " 5264: 'zone',\n",
       " 3087: 'nineteen85intro',\n",
       " 4756: 'trap',\n",
       " 4758: 'trapmoneybenny',\n",
       " 1618: 'feelings',\n",
       " 2429: 'kiki',\n",
       " 3814: 'riding',\n",
       " 5240: 'youll',\n",
       " 5204: 'ya',\n",
       " 2403: 'kb',\n",
       " 4805: 'try',\n",
       " 855: 'choices',\n",
       " 3903: 'runnin',\n",
       " 4419: 'stoppin',\n",
       " 4725: 'toppin',\n",
       " 5248: 'youve',\n",
       " 2546: 'learnin',\n",
       " 4091: 'shoppin',\n",
       " 4303: 'spend',\n",
       " 1426: 'earned',\n",
       " 3464: 'popped',\n",
       " 1524: 'ex',\n",
       " 1236: 'deserved',\n",
       " 2379: 'jump',\n",
       " 1002: 'confirmed',\n",
       " 2069: 'henny',\n",
       " 498: 'block',\n",
       " 2336: 'jenny',\n",
       " 4296: 'special',\n",
       " 3770: 'resha',\n",
       " 2368: 'jt',\n",
       " 2265: 'interlude',\n",
       " 2736: 'magnolia',\n",
       " 4095: 'shorty',\n",
       " 2447: 'kissin',\n",
       " 2448: 'kissinkissin',\n",
       " 2449: 'kisskissin',\n",
       " 464: 'black',\n",
       " 729: 'card',\n",
       " 948: 'code',\n",
       " 949: 'codecode',\n",
       " 3914: 'safesafe',\n",
       " 3050: 'neck',\n",
       " 3062: 'netflix',\n",
       " 849: 'chillwhats',\n",
       " 3063: 'netnetnet',\n",
       " 1193: 'ddown',\n",
       " 437: 'biggy',\n",
       " 1192: 'dddown',\n",
       " 4746: 'trade',\n",
       " 587: 'breakdown',\n",
       " 5032: 'wayne',\n",
       " 4156: 'skate',\n",
       " 235: 'ass',\n",
       " 363: 'bbring',\n",
       " 4062: 'shawty',\n",
       " 898: 'clap',\n",
       " 899: 'clapclap',\n",
       " 900: 'clapclapclap',\n",
       " 5252: 'yup',\n",
       " 475: 'blaqnmild',\n",
       " 1833: 'genius',\n",
       " 1274: 'diggin',\n",
       " 4167: 'skit',\n",
       " 5258: 'zazie',\n",
       " 386: 'beetz',\n",
       " 3360: 'photo',\n",
       " 2257: 'instagram',\n",
       " 5034: 'weak',\n",
       " 2663: 'lookpart',\n",
       " 2111: 'hol',\n",
       " 5253: 'yute',\n",
       " 4185: 'sleepin',\n",
       " 4440: 'streets',\n",
       " 4052: 'shaky',\n",
       " 5013: 'warrior',\n",
       " 3164: 'oliver',\n",
       " 3082: 'niko',\n",
       " 10: '15',\n",
       " 1741: 'fort',\n",
       " 5237: 'york',\n",
       " 5232: 'yknow',\n",
       " 5140: 'woes',\n",
       " 1069: 'countin',\n",
       " 1882: 'goes',\n",
       " 3505: 'pray',\n",
       " 2632: 'live',\n",
       " 1582: 'fakes',\n",
       " 1548: 'exposed',\n",
       " 1630: 'ferrari',\n",
       " 649: 'bugatti',\n",
       " 2180: 'hurt',\n",
       " 3848: 'rockin',\n",
       " 2347: 'jewelry',\n",
       " 3602: 'purpose',\n",
       " 4328: 'spot',\n",
       " 1235: 'deserve',\n",
       " 4051: 'shakiness',\n",
       " 4819: 'turned',\n",
       " 1651: 'fine',\n",
       " 3033: 'named',\n",
       " 2356: 'johnny',\n",
       " 1652: 'finer',\n",
       " 2353: 'job',\n",
       " 4014: 'sellin',\n",
       " 1847: 'girbaud',\n",
       " 2328: 'jeans',\n",
       " 5228: 'yellow',\n",
       " 4601: 'technomarine',\n",
       " 2398: 'kanye',\n",
       " 1383: 'dropped',\n",
       " 3449: 'polos',\n",
       " 289: 'backpacks',\n",
       " 1509: 'ethan',\n",
       " 3609: 'pushin',\n",
       " 4473: 'subaru',\n",
       " 2028: 'hatchback',\n",
       " 2022: 'hashtags',\n",
       " 373: 'beat',\n",
       " 2287: 'irrational',\n",
       " 1701: 'flow',\n",
       " 2267: 'international',\n",
       " 3766: 'reps',\n",
       " 3733: 'reign',\n",
       " 875: 'chubby',\n",
       " 4701: 'tj',\n",
       " 5120: 'winnie',\n",
       " 5087: 'whoa',\n",
       " 1208: 'declare',\n",
       " 2120: 'holiday',\n",
       " 306: 'baka',\n",
       " 3291: 'patch',\n",
       " 2787: 'mash',\n",
       " 2350: 'jibba',\n",
       " 5080: 'whip',\n",
       " 3812: 'ride',\n",
       " 3285: 'passenger',\n",
       " 4820: 'turnin',\n",
       " 4645: 'thinks',\n",
       " 22: '247',\n",
       " 2598: 'life',\n",
       " 2009: 'happened',\n",
       " 3459: 'popcaan',\n",
       " 4068: 'shell',\n",
       " 1554: 'eye',\n",
       " 3120: 'nuh',\n",
       " 1976: 'haffi',\n",
       " 2043: 'head',\n",
       " 541: 'book',\n",
       " 1410: 'dun',\n",
       " 4877: 'unruly',\n",
       " 1291: 'dis',\n",
       " 533: 'bomboclat',\n",
       " 3205: 'otha',\n",
       " 873: 'chromatic',\n",
       " 2384: 'jus',\n",
       " 4478: 'suck',\n",
       " 2726: 'mada',\n",
       " 199: 'apology',\n",
       " 5245: 'youth',\n",
       " 1147: 'cute',\n",
       " 1298: 'diss',\n",
       " 1532: 'execute',\n",
       " 2722: 'machine',\n",
       " 1955: 'gun',\n",
       " 4100: 'shots',\n",
       " 5141: 'woesintro',\n",
       " 2484: 'kyla',\n",
       " 4468: 'style',\n",
       " 1941: 'grips',\n",
       " 4979: 'waist',\n",
       " 3206: 'oti',\n",
       " 3204: 'ot',\n",
       " 3375: 'piece',\n",
       " 2068: 'hennessy',\n",
       " 1998: 'hand',\n",
       " 2085: 'higher',\n",
       " 3498: 'powers',\n",
       " 4563: 'taking',\n",
       " 4441: 'strength',\n",
       " 1951: 'guidance',\n",
       " 2748: 'makes',\n",
       " 1488: 'ends',\n",
       " 683: 'bust',\n",
       " 4128: 'silence',\n",
       " 4400: 'stick',\n",
       " 4621: 'text',\n",
       " 3760: 'reply',\n",
       " 1641: 'fighting',\n",
       " 5071: 'weve',\n",
       " 5137: 'wizkid',\n",
       " 3531: 'pretty',\n",
       " 5116: 'wine',\n",
       " 4201: 'slow',\n",
       " 1024: 'control',\n",
       " 2007: 'hannah',\n",
       " 5106: 'williams',\n",
       " 2050: 'heart',\n",
       " 2579: 'letting',\n",
       " 2322: 'jayz',\n",
       " 198: 'apologize',\n",
       " 5146: 'womanize',\n",
       " 842: 'child',\n",
       " 551: 'born',\n",
       " 5147: 'womans',\n",
       " 3044: 'natural',\n",
       " 4833: 'twins',\n",
       " 398: 'believe',\n",
       " 2913: 'miracles',\n",
       " 4267: 'song',\n",
       " 2012: 'harassed',\n",
       " 3271: 'paris',\n",
       " 3861: 'rome',\n",
       " 4566: 'talked',\n",
       " 2155: 'hours',\n",
       " 3366: 'pick',\n",
       " 1471: 'embarrass',\n",
       " 2258: 'instead',\n",
       " 3568: 'proposal',\n",
       " 4386: 'steady',\n",
       " 20: '21st',\n",
       " 449: 'birthday',\n",
       " 2806: 'matured',\n",
       " 1601: 'faster',\n",
       " 2248: 'innocence',\n",
       " 2981: 'mourn',\n",
       " 1200: 'death',\n",
       " 4403: 'stillborns',\n",
       " 3523: 'present',\n",
       " 528: 'body',\n",
       " 5179: 'wouldnt',\n",
       " 78: 'accept',\n",
       " 4742: 'toyed',\n",
       " 1480: 'emotions',\n",
       " 1479: 'emotionless',\n",
       " 420: 'best',\n",
       " 4093: 'short',\n",
       " 4276: 'soul',\n",
       " 2157: 'housed',\n",
       " 4365: 'stare',\n",
       " 473: 'blankly',\n",
       " 4288: 'space',\n",
       " 5020: 'wasted',\n",
       " 346: 'basic',\n",
       " 2438: 'kim',\n",
       " 679: 'burrell',\n",
       " 4765: 'treat',\n",
       " 3153: 'ohhhhhh',\n",
       " 135: 'ages',\n",
       " 1020: 'contained',\n",
       " 3677: 'ratchet',\n",
       " 1539: 'expansive',\n",
       " 2765: 'mansions',\n",
       " 4184: 'sleep',\n",
       " 4510: 'supposed',\n",
       " 4895: 'vacay',\n",
       " 4684: 'til',\n",
       " 290: 'backs',\n",
       " 676: 'burn',\n",
       " 2523: 'laugh',\n",
       " 4421: 'stops',\n",
       " 2837: 'meet',\n",
       " 1179: 'dark',\n",
       " 2851: 'men',\n",
       " 1146: 'cut',\n",
       " 3110: 'nose',\n",
       " 4319: 'spite',\n",
       " 5003: 'wanted',\n",
       " 5145: 'woman',\n",
       " 3561: 'promised',\n",
       " 1105: 'cried',\n",
       " 1337: 'doover',\n",
       " 1478: 'emotionally',\n",
       " 263: 'available',\n",
       " 2280: 'invited',\n",
       " 4399: 'stew',\n",
       " 844: 'children',\n",
       " 3545: 'probly',\n",
       " 4054: 'shame',\n",
       " 3025: 'ménage',\n",
       " 4787: 'trois',\n",
       " 4277: 'soulmate',\n",
       " 3834: 'risked',\n",
       " 513: 'blue',\n",
       " 4502: 'superhero',\n",
       " 591: 'breaks',\n",
       " 1543: 'explain',\n",
       " 2788: 'mask',\n",
       " 3936: 'santa',\n",
       " 906: 'claus',\n",
       " 3173: 'online',\n",
       " 516: 'blues',\n",
       " 4722: 'tooth',\n",
       " 1578: 'fairy',\n",
       " 3297: 'pay',\n",
       " 4105: 'shouldproduced',\n",
       " 3809: 'rick',\n",
       " 3887: 'rubin',\n",
       " 2037: 'havin',\n",
       " 3295: 'patrol',\n",
       " 1814: 'gat',\n",
       " 1712: 'foes',\n",
       " 750: 'caskets',\n",
       " 1114: 'critics',\n",
       " 747: 'cash',\n",
       " 2136: 'hood',\n",
       " 4467: 'stupid',\n",
       " 1564: 'facts',\n",
       " 1935: 'grew',\n",
       " 2119: 'holes',\n",
       " 5256: 'zapatos',\n",
       " 771: 'celebrate',\n",
       " 2911: 'minute',\n",
       " 1349: 'dough',\n",
       " 2446: 'kiss',\n",
       " 237: 'asshole',\n",
       " 2713: 'lyrics',\n",
       " 3526: 'press',\n",
       " 1600: 'fast',\n",
       " 382: 'beef',\n",
       " 3638: 'radio',\n",
       " 2738: 'mags',\n",
       " 4887: 'use',\n",
       " 119: 'advertisers',\n",
       " 115: 'ads',\n",
       " 1786: 'fuckers',\n",
       " 2262: 'intelligence',\n",
       " 2321: 'jay',\n",
       " 3641: 'rags',\n",
       " 3807: 'riches',\n",
       " 1406: 'dumb',\n",
       " 60: '94',\n",
       " 4801: 'trunk',\n",
       " 3680: 'raw',\n",
       " 3704: 'rearview',\n",
       " 2915: 'mirror',\n",
       " 2972: 'motherfuckin',\n",
       " 2529: 'law',\n",
       " 561: 'bounce',\n",
       " 1250: 'devil',\n",
       " 3314: 'pedal',\n",
       " 2091: 'highway',\n",
       " 810: 'chase',\n",
       " 2313: 'jake',\n",
       " 3430: 'plus',\n",
       " 1319: 'dollars',\n",
       " 1640: 'fight',\n",
       " 746: 'case',\n",
       " 4420: 'stopping',\n",
       " 5241: 'young',\n",
       " 2035: 'hats',\n",
       " 2691: 'low',\n",
       " 3688: 'reader',\n",
       " 4148: 'sir',\n",
       " 215: 'arrest',\n",
       " 44: '55',\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word # if I want to see the first few Items I am going to need to import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:17:20.692940Z",
     "start_time": "2019-05-15T20:17:16.860488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"verse\" + 0.007*\"life\" + 0.006*\"bitch\" + 0.006*\"chorus\" + 0.005*\"just\" + 0.005*\"ass\" + 0.004*\"high\" + 0.004*\"new\" + 0.004*\"em\" + 0.004*\"time\"'),\n",
       " (1,\n",
       "  '0.010*\"just\" + 0.006*\"need\" + 0.006*\"verse\" + 0.006*\"chorus\" + 0.005*\"want\" + 0.005*\"say\" + 0.004*\"bitch\" + 0.004*\"time\" + 0.004*\"make\" + 0.004*\"em\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the LDA model\n",
    "\n",
    "lda = models.LdaModel(\n",
    "    corpus=corpus, # this our term document matrix\n",
    "    id2word=id2word, # this our dict of location:term\n",
    "    num_topics=2, # choosing two topics the model will try to discover\n",
    "    passes=10, # we will start with 10 passes and see what difference it makes moving up or down.\n",
    "              # this will go through the document once searching for the best topics based off the document. I'm asking it to do it 10x.\n",
    "              # the more passes the more the topics begin to make sense.\n",
    "    random_state = 42\n",
    ")\n",
    "# print the discovered topics out\n",
    "lda.print_topics()\n",
    "# the output will show you the top words of the topic. It will not output the topic itself.\n",
    "# this output probably won't make much sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the topics count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:18:23.395001Z",
     "start_time": "2019-05-15T20:18:19.697243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"just\" + 0.007*\"verse\" + 0.007*\"chorus\" + 0.007*\"bitch\" + 0.006*\"ass\" + 0.006*\"life\" + 0.005*\"need\" + 0.005*\"make\" + 0.005*\"real\" + 0.005*\"time\"'),\n",
       " (1,\n",
       "  '0.009*\"just\" + 0.005*\"say\" + 0.005*\"let\" + 0.005*\"em\" + 0.004*\"fuckin\" + 0.004*\"think\" + 0.004*\"better\" + 0.004*\"bitch\" + 0.004*\"verse\" + 0.004*\"yall\"'),\n",
       " (2,\n",
       "  '0.007*\"verse\" + 0.006*\"chorus\" + 0.005*\"just\" + 0.005*\"black\" + 0.005*\"bitch\" + 0.005*\"life\" + 0.005*\"em\" + 0.005*\"west\" + 0.004*\"kanye\" + 0.004*\"want\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try 3 topics\n",
    "lda = models.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=3,\n",
    "    passes=10,\n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "lda.print_topics()\n",
    "# not getting anything better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:19:11.753366Z",
     "start_time": "2019-05-15T20:19:08.153059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"just\" + 0.008*\"verse\" + 0.007*\"chorus\" + 0.007*\"bitch\" + 0.007*\"ass\" + 0.006*\"life\" + 0.005*\"need\" + 0.005*\"make\" + 0.005*\"real\" + 0.005*\"time\"'),\n",
       " (1,\n",
       "  '0.010*\"just\" + 0.005*\"let\" + 0.005*\"say\" + 0.005*\"em\" + 0.005*\"fuckin\" + 0.005*\"think\" + 0.005*\"better\" + 0.004*\"bitch\" + 0.004*\"verse\" + 0.004*\"yall\"'),\n",
       " (2,\n",
       "  '0.007*\"verse\" + 0.006*\"chorus\" + 0.006*\"just\" + 0.005*\"black\" + 0.005*\"bitch\" + 0.005*\"life\" + 0.005*\"em\" + 0.005*\"west\" + 0.005*\"kanye\" + 0.004*\"want\"'),\n",
       " (3,\n",
       "  '0.000*\"just\" + 0.000*\"verse\" + 0.000*\"time\" + 0.000*\"bitch\" + 0.000*\"life\" + 0.000*\"chorus\" + 0.000*\"ass\" + 0.000*\"make\" + 0.000*\"need\" + 0.000*\"em\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try 4\n",
    "# let's try 3 topics\n",
    "lda = models.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=4,\n",
    "    passes=10,\n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "lda.print_topics()\n",
    "# not getting anything better...again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to need to go back and clean much more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust the number of passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:21:13.333194Z",
     "start_time": "2019-05-15T20:20:55.452465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"just\" + 0.007*\"verse\" + 0.007*\"chorus\" + 0.007*\"bitch\" + 0.006*\"ass\" + 0.006*\"life\" + 0.005*\"need\" + 0.005*\"real\" + 0.005*\"make\" + 0.005*\"high\"'),\n",
       " (1,\n",
       "  '0.009*\"just\" + 0.005*\"let\" + 0.005*\"say\" + 0.005*\"em\" + 0.004*\"fuckin\" + 0.004*\"better\" + 0.004*\"think\" + 0.004*\"bitch\" + 0.004*\"yall\" + 0.004*\"verse\"'),\n",
       " (2,\n",
       "  '0.007*\"verse\" + 0.006*\"chorus\" + 0.005*\"just\" + 0.005*\"black\" + 0.005*\"bitch\" + 0.005*\"west\" + 0.005*\"em\" + 0.005*\"life\" + 0.004*\"kanye\" + 0.004*\"big\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll use 4 topics w/ 50 passes\n",
    "lda = models.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=3,\n",
    "    passes=50,\n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "lda.print_topics()\n",
    "# that didn't seem to work any better. One last shot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:37:28.008914Z",
     "start_time": "2019-05-15T20:36:53.425069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"just\" + 0.007*\"verse\" + 0.007*\"chorus\" + 0.007*\"bitch\" + 0.006*\"ass\" + 0.006*\"life\" + 0.005*\"need\" + 0.005*\"real\" + 0.005*\"make\" + 0.005*\"high\"'),\n",
       " (1,\n",
       "  '0.009*\"just\" + 0.005*\"let\" + 0.005*\"say\" + 0.005*\"em\" + 0.004*\"fuckin\" + 0.004*\"better\" + 0.004*\"think\" + 0.004*\"bitch\" + 0.004*\"yall\" + 0.004*\"verse\"'),\n",
       " (2,\n",
       "  '0.007*\"verse\" + 0.006*\"chorus\" + 0.005*\"just\" + 0.005*\"black\" + 0.005*\"bitch\" + 0.005*\"west\" + 0.005*\"em\" + 0.005*\"life\" + 0.004*\"kanye\" + 0.004*\"big\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll try w/ 100 passes\n",
    "lda = models.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=3,\n",
    "    passes=100,\n",
    "#     distributed=True, # This will not work without a module named Pyro4\n",
    "    random_state= 42,\n",
    "    per_word_topics=False # prints the list of topics (not working)\n",
    ")\n",
    "\n",
    "lda.print_topics()\n",
    "# still the same..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:45:07.356428Z",
     "start_time": "2019-05-15T20:45:07.347651Z"
    }
   },
   "outputs": [],
   "source": [
    "def nouns(text):\n",
    "    \"\"\"\n",
    "    pull out the nouns only from a string of text\n",
    "    \"\"\"\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:45:07.704902Z",
     "start_time": "2019-05-15T20:45:07.687380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Artist Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drake</th>\n",
       "      <td>produced by boi1da frank dukes noah 40 shebib ...</td>\n",
       "      <td>Drake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jayz</th>\n",
       "      <td>intro hannah williams do i find it so hard whe...</td>\n",
       "      <td>Jayz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nas</th>\n",
       "      <td>produced by ron browz intro fuck jay z whats u...</td>\n",
       "      <td>Nas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>verse 1 now this shits about to kick off this ...</td>\n",
       "      <td>Eminem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future</th>\n",
       "      <td>intro high klassified な音楽 i got the truth in m...</td>\n",
       "      <td>Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KanyeWest</th>\n",
       "      <td>produced by daft punk  kanye west verse 1 for ...</td>\n",
       "      <td>KanyeWest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Lyrics Artist Name\n",
       "Artist                                                                  \n",
       "Drake      produced by boi1da frank dukes noah 40 shebib ...       Drake\n",
       "Jayz       intro hannah williams do i find it so hard whe...        Jayz\n",
       "Nas        produced by ron browz intro fuck jay z whats u...         Nas\n",
       "Eminem     verse 1 now this shits about to kick off this ...      Eminem\n",
       "Future     intro high klassified な音楽 i got the truth in m...      Future\n",
       "KanyeWest  produced by daft punk  kanye west verse 1 for ...   KanyeWest"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the cleaned data to gather the nouns\n",
    "data_clean = pd.read_pickle('DataFrame_Corpus.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T20:46:47.887143Z",
     "start_time": "2019-05-15T20:46:43.343632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drake</th>\n",
       "      <td>boi1da frank dukes shebib part verse fuck bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jayz</th>\n",
       "      <td>intro hannah williams i heart im day day look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nas</th>\n",
       "      <td>ron browz fuck jay z ayo i z dick nigga style ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>party lets hiphop scratch im bout track everyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future</th>\n",
       "      <td>な音楽 i truth weeknd dont dance moves nigga sham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KanyeWest</th>\n",
       "      <td>daft punk kanye verse theme song jeans byanyme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Lyrics\n",
       "Artist                                                      \n",
       "Drake      boi1da frank dukes shebib part verse fuck bein...\n",
       "Jayz       intro hannah williams i heart im day day look ...\n",
       "Nas        ron browz fuck jay z ayo i z dick nigga style ...\n",
       "Eminem     party lets hiphop scratch im bout track everyb...\n",
       "Future     な音楽 i truth weeknd dont dance moves nigga sham...\n",
       "KanyeWest  daft punk kanye verse theme song jeans byanyme..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the noun function that was created above\n",
    "data_nouns = pd.DataFrame(data_clean.Lyrics.apply(nouns))\n",
    "data_nouns\n",
    "# below you will see the corpus with nouns only. It seems like some\n",
    "# words just don't belong like the word 'moves' but notice the word dance next\n",
    "# to it. That makes it a noun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:18.660354Z",
     "start_time": "2019-05-15T22:12:18.596480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>ability</th>\n",
       "      <th>abundance</th>\n",
       "      <th>accelerants</th>\n",
       "      <th>accolades</th>\n",
       "      <th>account</th>\n",
       "      <th>accounts</th>\n",
       "      <th>ace</th>\n",
       "      <th>acetaminophen</th>\n",
       "      <th>...</th>\n",
       "      <th>yung</th>\n",
       "      <th>zapatos</th>\n",
       "      <th>zazie</th>\n",
       "      <th>ze</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zip</th>\n",
       "      <th>zod</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zonin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drake</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jayz</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nas</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KanyeWest</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 3332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           a1  aaaah  ability  abundance  accelerants  accolades  account  \\\n",
       "Artist                                                                      \n",
       "Drake       0      0        0          0            0          0        0   \n",
       "Jayz        0      0        0          0            0          0        0   \n",
       "Nas         0      0        0          1            0          0        0   \n",
       "Eminem      0      0        1          0            1          1        1   \n",
       "Future      0      0        0          0            0          0        1   \n",
       "KanyeWest   1      1        0          0            0          0        0   \n",
       "\n",
       "           accounts  ace  acetaminophen  ...  yung  zapatos  zazie  ze  zeros  \\\n",
       "Artist                                   ...                                    \n",
       "Drake             0    0              0  ...     0        0      1   0      0   \n",
       "Jayz              0    0              0  ...     0        1      0   0      0   \n",
       "Nas               1    1              0  ...     0        0      0   1      1   \n",
       "Eminem            0    1              1  ...     1        0      0   0      0   \n",
       "Future            0    1              0  ...     0        0      0   0      0   \n",
       "KanyeWest         1    0              0  ...     0        0      0   0      0   \n",
       "\n",
       "           zip  zod  zombie  zone  zonin  \n",
       "Artist                                    \n",
       "Drake        1    0       0     1      0  \n",
       "Jayz         0    0       0     0      0  \n",
       "Nas          0    0       0     0      0  \n",
       "Eminem       0    1       1     0      0  \n",
       "Future       0    0       0     0      0  \n",
       "KanyeWest    0    0       1     0      3  \n",
       "\n",
       "[6 rows x 3332 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# okay now we have to do the same steps above all over again\n",
    "# meaning we need another term document matrix and another dictionary \n",
    "# before modeling. \n",
    "\n",
    "# right now our tdm doesn not have stop words in it. Re-add them\n",
    "add_stop_words = [ # inside this list I will insert words that just shouldn't be considered\n",
    "    'な音楽','verse','produced','intro','just','em','chorus',\n",
    "    'bitch','kanye','west','boi1da','ass','yall', 'zöld',\n",
    "    'ölén','úgy', 'im',\n",
    "    \n",
    "    'fuck','fucking','fucks','fuckin','nigga','niggas','shit', \n",
    "    'bitch','bitches','pussy','hoes','muhfucka','motherfucker',\n",
    "    'ass',\n",
    "    \n",
    "    'lets','cause','thats', 'youre','aint', 'yeah', 'future','nas',\n",
    "    'drake'\n",
    "]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Create a document term matrix to turn into a term document matrix\n",
    "cvn = CountVectorizer(\n",
    "    stop_words=stop_words\n",
    ")\n",
    "data_cvn = cvn.fit_transform(\n",
    "    data_nouns.Lyrics\n",
    ")\n",
    "data_dtmn = pd.DataFrame(\n",
    "    data_cvn.toarray(),\n",
    "    columns = cvn.get_feature_names()\n",
    ")\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:19.440590Z",
     "start_time": "2019-05-15T22:12:19.426811Z"
    }
   },
   "outputs": [],
   "source": [
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "id2wordn = dict((v,k) for k,v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:22.319478Z",
     "start_time": "2019-05-15T22:12:20.086846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"clique\" + 0.009*\"swerve\" + 0.005*\"girl\" + 0.005*\"money\" + 0.005*\"hands\" + 0.005*\"monster\" + 0.004*\"life\" + 0.004*\"teeth\" + 0.004*\"sound\" + 0.004*\"need\"'),\n",
       " (1,\n",
       "  '0.011*\"love\" + 0.009*\"life\" + 0.009*\"time\" + 0.008*\"world\" + 0.008*\"man\" + 0.006*\"day\" + 0.006*\"dont\" + 0.005*\"way\" + 0.005*\"money\" + 0.004*\"thou\"')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the LDA model\n",
    "\n",
    "ldan = models.LdaModel(\n",
    "    corpus=corpusn, # this our term document matrix\n",
    "    id2word=id2wordn, # this our dict of location:term\n",
    "    num_topics=2, # choosing two topics the model will try to discover\n",
    "    passes=10, # we will start with 10 passes and see what difference it makes moving up or down.\n",
    "              # this will go through the document once searching for the best topics based off the document. I'm asking it to do it 10x.\n",
    "              # the more passes the more the topics begin to make sense.\n",
    "    random_state = 42\n",
    ")\n",
    "# print the discovered topics out\n",
    "ldan.print_topics()\n",
    "# the output will show you the top words of the topic. It will not output the topic itself.\n",
    "# this is starting look decent as an output do to the stop words, \n",
    "# which only reinforces that I need to clean better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:33.186670Z",
     "start_time": "2019-05-15T22:12:22.931258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"clique\" + 0.011*\"swerve\" + 0.006*\"girl\" + 0.006*\"hands\" + 0.006*\"money\" + 0.006*\"monster\" + 0.005*\"life\" + 0.005*\"sound\" + 0.005*\"teeth\" + 0.005*\"need\"'),\n",
       " (1,\n",
       "  '0.008*\"time\" + 0.008*\"day\" + 0.007*\"dont\" + 0.007*\"man\" + 0.006*\"way\" + 0.006*\"love\" + 0.005*\"face\" + 0.005*\"girl\" + 0.005*\"home\" + 0.004*\"water\"'),\n",
       " (2,\n",
       "  '0.015*\"love\" + 0.015*\"world\" + 0.015*\"life\" + 0.009*\"thou\" + 0.009*\"time\" + 0.009*\"man\" + 0.007*\"trophy\" + 0.006*\"dog\" + 0.006*\"commas\" + 0.006*\"money\"')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying 3 topics w/ 50 passes\n",
    "ldan = models.LdaModel(\n",
    "    corpus=corpusn,\n",
    "    id2word=id2wordn,\n",
    "    num_topics=3,\n",
    "    passes=50,\n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:44.353215Z",
     "start_time": "2019-05-15T22:12:33.736866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.020*\"clique\" + 0.012*\"swerve\" + 0.007*\"girl\" + 0.007*\"hands\" + 0.007*\"money\" + 0.006*\"monster\" + 0.006*\"life\" + 0.005*\"sound\" + 0.005*\"teeth\" + 0.005*\"need\"'),\n",
       " (1,\n",
       "  '0.009*\"time\" + 0.008*\"day\" + 0.008*\"dont\" + 0.007*\"man\" + 0.007*\"way\" + 0.007*\"love\" + 0.005*\"face\" + 0.005*\"girl\" + 0.005*\"home\" + 0.004*\"water\"'),\n",
       " (2,\n",
       "  '0.018*\"life\" + 0.018*\"thou\" + 0.014*\"trophy\" + 0.013*\"dog\" + 0.013*\"commas\" + 0.010*\"money\" + 0.009*\"percocets\" + 0.008*\"time\" + 0.007*\"wifey\" + 0.007*\"foreigns\"'),\n",
       " (3,\n",
       "  '0.023*\"world\" + 0.023*\"love\" + 0.012*\"man\" + 0.009*\"represent\" + 0.009*\"life\" + 0.008*\"time\" + 0.006*\"mind\" + 0.006*\"son\" + 0.005*\"death\" + 0.005*\"state\"')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying 4 topics w/ 50 passes\n",
    "ldan = models.LdaModel(\n",
    "    corpus=corpusn,\n",
    "    id2word=id2wordn,\n",
    "    num_topics=4,\n",
    "    passes=50,\n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouns and Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:44.975100Z",
     "start_time": "2019-05-15T22:12:44.966463Z"
    }
   },
   "outputs": [],
   "source": [
    "def noun_adj(text):\n",
    "    \"\"\"\n",
    "    Same as nouns above, but now including adjectives too.\n",
    "    \"\"\"\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word,pos) in pos_tag(tokenized) if is_noun_adj (pos)]\n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:50.014821Z",
     "start_time": "2019-05-15T22:12:45.615050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drake</th>\n",
       "      <td>boi1da frank dukes shebib nineteen85 part vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jayz</th>\n",
       "      <td>intro hannah williams hard i heart im day day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nas</th>\n",
       "      <td>ron browz intro fuck jay z niggas ayo i aint j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>verse party wack lets hiphop scratch im bout t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future</th>\n",
       "      <td>high な音楽 i truth verse weeknd nigga dont dance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KanyeWest</th>\n",
       "      <td>daft punk kanye west verse theme song black le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Lyrics\n",
       "Artist                                                      \n",
       "Drake      boi1da frank dukes shebib nineteen85 part vers...\n",
       "Jayz       intro hannah williams hard i heart im day day ...\n",
       "Nas        ron browz intro fuck jay z niggas ayo i aint j...\n",
       "Eminem     verse party wack lets hiphop scratch im bout t...\n",
       "Future     high な音楽 i truth verse weeknd nigga dont dance...\n",
       "KanyeWest  daft punk kanye west verse theme song black le..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adj = pd.DataFrame(data_clean.Lyrics.apply(noun_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:50.712431Z",
     "start_time": "2019-05-15T22:12:50.603102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21st</th>\n",
       "      <th>41st</th>\n",
       "      <th>a1</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abundance</th>\n",
       "      <th>ac</th>\n",
       "      <th>accelerants</th>\n",
       "      <th>...</th>\n",
       "      <th>yung</th>\n",
       "      <th>zapatos</th>\n",
       "      <th>zazie</th>\n",
       "      <th>ze</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zip</th>\n",
       "      <th>zod</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zonin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drake</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jayz</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nas</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Future</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KanyeWest</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 4045 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           21st  41st  a1  aaaah  ability  able  absurd  abundance  ac  \\\n",
       "Artist                                                                   \n",
       "Drake         0     0   0      0        0     0       0          0   0   \n",
       "Jayz          1     0   0      0        0     0       0          0   0   \n",
       "Nas           0     1   0      0        0     0       0          1   0   \n",
       "Eminem        0     0   0      0        1     2       1          0   1   \n",
       "Future        0     0   0      0        0     0       0          0   0   \n",
       "KanyeWest     0     0   1      1        0     0       0          0   0   \n",
       "\n",
       "           accelerants  ...  yung  zapatos  zazie  ze  zeros  zip  zod  \\\n",
       "Artist                  ...                                              \n",
       "Drake                0  ...     0        0      1   0      0    1    0   \n",
       "Jayz                 0  ...     0        1      0   0      0    0    0   \n",
       "Nas                  0  ...     0        0      0   1      1    0    0   \n",
       "Eminem               1  ...     1        0      0   0      0    0    1   \n",
       "Future               0  ...     0        0      0   0      0    0    0   \n",
       "KanyeWest            0  ...     0        0      0   0      0    0    0   \n",
       "\n",
       "           zombie  zone  zonin  \n",
       "Artist                          \n",
       "Drake           0     1      0  \n",
       "Jayz            0     0      0  \n",
       "Nas             0     0      0  \n",
       "Eminem          1     0      0  \n",
       "Future          0     0      0  \n",
       "KanyeWest       1     0      3  \n",
       "\n",
       "[6 rows x 4045 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate countvectorizer\n",
    "cvna = CountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "#     max_df=.8 # consider adding this in, see what difference it makes\n",
    ")\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.Lyrics)\n",
    "data_dtmna = pd.DataFrame (data_cvna.toarray(), columns = cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:51.519761Z",
     "start_time": "2019-05-15T22:12:51.509269Z"
    }
   },
   "outputs": [],
   "source": [
    "# create our sparse matrix and vocab dictionary\n",
    "corpusna = matutils.Sparse2Corpus(\n",
    "    scipy.sparse.csr_matrix(data_dtmna.transpose())\n",
    ")\n",
    "\n",
    "id2wordna = dict((v,k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:12:54.679433Z",
     "start_time": "2019-05-15T22:12:52.097518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"life\" + 0.009*\"love\" + 0.008*\"world\" + 0.006*\"high\" + 0.006*\"new\" + 0.005*\"time\" + 0.005*\"man\" + 0.005*\"day\" + 0.005*\"low\" + 0.005*\"thou\"'),\n",
       " (1,\n",
       "  '0.006*\"dont\" + 0.006*\"time\" + 0.006*\"clique\" + 0.005*\"man\" + 0.005*\"god\" + 0.005*\"girl\" + 0.005*\"way\" + 0.004*\"love\" + 0.004*\"real\" + 0.004*\"night\"')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to model. We will start with 2 and move to 4\n",
    "\n",
    "ldana = models.LdaModel(\n",
    "    corpus=corpusna,\n",
    "    id2word=id2wordna,\n",
    "    num_topics=2,\n",
    "    passes=10\n",
    ")\n",
    "\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:13:08.035386Z",
     "start_time": "2019-05-15T22:12:55.211460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"clique\" + 0.008*\"girl\" + 0.007*\"god\" + 0.007*\"real\" + 0.007*\"time\" + 0.006*\"swerve\" + 0.006*\"love\" + 0.006*\"man\" + 0.006*\"black\" + 0.005*\"big\"'),\n",
       " (1,\n",
       "  '0.008*\"life\" + 0.007*\"high\" + 0.007*\"dont\" + 0.007*\"thou\" + 0.006*\"low\" + 0.006*\"time\" + 0.006*\"ta\" + 0.005*\"trophy\" + 0.005*\"gon\" + 0.005*\"dog\"'),\n",
       " (2,\n",
       "  '0.013*\"love\" + 0.012*\"world\" + 0.008*\"new\" + 0.007*\"man\" + 0.006*\"black\" + 0.006*\"life\" + 0.006*\"york\" + 0.006*\"day\" + 0.005*\"represent\" + 0.005*\"time\"')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 topics with 50 passes\n",
    "ldana = models.LdaModel(\n",
    "    corpus=corpusna,\n",
    "    id2word=id2wordna,\n",
    "    num_topics=3,\n",
    "    passes=50\n",
    ")\n",
    "\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T22:17:52.620930Z",
     "start_time": "2019-05-15T22:13:08.673241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"hold\" + 0.000*\"insane\" + 0.000*\"hit\" + 0.000*\"story\" + 0.000*\"watch\" + 0.000*\"roll\" + 0.000*\"mama\" + 0.000*\"reason\" + 0.000*\"lord\" + 0.000*\"code\"'),\n",
       " (1,\n",
       "  '0.010*\"love\" + 0.009*\"world\" + 0.006*\"man\" + 0.006*\"new\" + 0.006*\"dont\" + 0.006*\"day\" + 0.005*\"time\" + 0.005*\"life\" + 0.005*\"black\" + 0.004*\"york\"'),\n",
       " (2,\n",
       "  '0.014*\"high\" + 0.014*\"life\" + 0.014*\"thou\" + 0.013*\"low\" + 0.011*\"trophy\" + 0.010*\"dog\" + 0.010*\"commas\" + 0.008*\"money\" + 0.007*\"percocets\" + 0.007*\"strong\"'),\n",
       " (3,\n",
       "  '0.011*\"clique\" + 0.008*\"girl\" + 0.008*\"real\" + 0.008*\"god\" + 0.007*\"time\" + 0.007*\"love\" + 0.007*\"swerve\" + 0.007*\"man\" + 0.006*\"black\" + 0.006*\"way\"')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 topics with 1000 passes\n",
    "ldana = models.LdaModel(\n",
    "    corpus=corpusna,\n",
    "    id2word=id2wordna,\n",
    "    num_topics=4,\n",
    "    passes=1000\n",
    ")\n",
    "\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to have to interpret the topics. Very subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
